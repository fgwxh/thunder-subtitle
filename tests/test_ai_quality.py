"""
å­—å¹•è´¨é‡AIè¯„ä¼°æµ‹è¯•è„šæœ¬
æ”¯æŒå¤šç§AIåç«¯ï¼šOpenAIã€DeepSeekã€æœ¬åœ°æ¨¡å‹ç­‰
"""
import asyncio
import sys
import os
import re
import json
import time

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.thunder_subtitle_cli.client import ThunderClient


def extract_text_from_srt(content: str) -> str:
    """ä»SRTæ ¼å¼ä¸­æå–çº¯æ–‡æœ¬"""
    lines = content.split('\n')
    text_lines = []
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        if line.isdigit():
            continue
        if '-->' in line:
            continue
        text_lines.append(line)
    
    return '\n'.join(text_lines)


def extract_text_from_ass(content: str) -> str:
    """ä»ASSæ ¼å¼ä¸­æå–çº¯æ–‡æœ¬"""
    lines = content.split('\n')
    text_lines = []
    in_events = False
    
    for line in lines:
        line = line.strip()
        
        if line.startswith('[Events]'):
            in_events = True
            continue
        
        if line.startswith('[') and in_events:
            break
        
        if in_events and line.startswith('Dialogue:'):
            parts = line.split(',', 9)
            if len(parts) >= 10:
                text = parts[9]
                text = re.sub(r'\{[^}]*\}', '', text)
                text = re.sub(r'\\N', '\n', text)
                text = text.strip()
                if text:
                    text_lines.append(text)
    
    return '\n'.join(text_lines)


def extract_text(content: str, ext: str) -> str:
    """æ ¹æ®æ‰©å±•åæå–æ–‡æœ¬"""
    ext = ext.lower().lstrip('.')
    if ext == 'ass':
        return extract_text_from_ass(content)
    else:
        return extract_text_from_srt(content)


class AIQualityEvaluator:
    """AIè´¨é‡è¯„ä¼°å™¨åŸºç±»"""
    
    async def evaluate(self, text: str) -> dict:
        raise NotImplementedError


class OpenAIEvaluator(AIQualityEvaluator):
    """OpenAI APIè¯„ä¼°å™¨"""
    
    def __init__(self, api_key: str = None, base_url: str = None, model: str = "gpt-3.5-turbo"):
        self.api_key = api_key or os.environ.get("OPENAI_API_KEY")
        self.base_url = base_url or os.environ.get("OPENAI_BASE_URL", "https://api.openai.com/v1")
        self.model = model
    
    async def evaluate(self, text: str) -> dict:
        if not self.api_key:
            return {"error": "æœªé…ç½®OpenAI API Key", "available": False}
        
        try:
            import aiohttp
            
            prompt = f"""è¯·è¯„ä¼°ä»¥ä¸‹å­—å¹•æ–‡æœ¬çš„ç¿»è¯‘è´¨é‡ã€‚

å­—å¹•æ–‡æœ¬ï¼ˆå‰1000å­—ç¬¦ï¼‰:
{text[:1000]}

è¯·ä»ä»¥ä¸‹ç»´åº¦è¯„ä¼°ï¼Œæ¯é¡¹0-10åˆ†ï¼š
1. æµç•…åº¦ï¼šè¯­å¥æ˜¯å¦é€šé¡ºè‡ªç„¶
2. å‡†ç¡®åº¦ï¼šç¿»è¯‘æ˜¯å¦å‡†ç¡®ä¼ è¾¾åŸæ„
3. æœ¬åœ°åŒ–ï¼šæ˜¯å¦ç¬¦åˆä¸­æ–‡è¡¨è¾¾ä¹ æƒ¯
4. ä¸“ä¸šæ€§ï¼šä¸“ä¸šæœ¯è¯­ç¿»è¯‘æ˜¯å¦æ°å½“

è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼š
{{
    "fluency": åˆ†æ•°,
    "accuracy": åˆ†æ•°,
    "localization": åˆ†æ•°,
    "professionalism": åˆ†æ•°,
    "overall_score": ç»¼åˆåˆ†æ•°(0-100),
    "is_machine_translation": true/false,
    "issues": ["é—®é¢˜1", "é—®é¢˜2"],
    "summary": "ç®€çŸ­è¯„ä»·"
}}"""

            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.base_url}/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": self.model,
                        "messages": [
                            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­—å¹•ç¿»è¯‘è´¨é‡è¯„ä¼°ä¸“å®¶ã€‚è¯·å®¢è§‚è¯„ä¼°å­—å¹•è´¨é‡ï¼Œè¯†åˆ«æœºå™¨ç¿»è¯‘ç—•è¿¹ã€‚"},
                            {"role": "user", "content": prompt}
                        ],
                        "temperature": 0.3,
                        "max_tokens": 500
                    },
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    if response.status != 200:
                        return {"error": f"APIè¯·æ±‚å¤±è´¥: {response.status}", "available": False}
                    
                    data = await response.json()
                    content = data["choices"][0]["message"]["content"]
                    
                    json_match = re.search(r'\{[\s\S]*\}', content)
                    if json_match:
                        result = json.loads(json_match.group())
                        result["available"] = True
                        return result
                    else:
                        return {"error": "æ— æ³•è§£æAIå“åº”", "raw": content, "available": False}
                        
        except Exception as e:
            return {"error": str(e), "available": False}


class DeepSeekEvaluator(AIQualityEvaluator):
    """DeepSeek APIè¯„ä¼°å™¨"""
    
    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.environ.get("DEEPSEEK_API_KEY")
        self.base_url = "https://api.deepseek.com/v1"
    
    async def evaluate(self, text: str) -> dict:
        if not self.api_key:
            return {"error": "æœªé…ç½®DeepSeek API Key", "available": False}
        
        evaluator = OpenAIEvaluator(
            api_key=self.api_key,
            base_url=self.base_url,
            model="deepseek-chat"
        )
        return await evaluator.evaluate(text)


class LocalModelEvaluator(AIQualityEvaluator):
    """æœ¬åœ°æ¨¡å‹è¯„ä¼°å™¨ï¼ˆä½¿ç”¨transformersï¼‰"""
    
    def __init__(self):
        self.model = None
        self.tokenizer = None
    
    def _load_model(self):
        try:
            from transformers import pipeline
            if self.model is None:
                print("æ­£åœ¨åŠ è½½æœ¬åœ°æ¨¡å‹...")
                self.model = pipeline(
                    "text-classification",
                    model="bert-base-chinese",
                    device=-1
                )
            return True
        except ImportError:
            return False
        except Exception as e:
            print(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            return False
    
    async def evaluate(self, text: str) -> dict:
        if not self._load_model():
            return {"error": "æ— æ³•åŠ è½½æœ¬åœ°æ¨¡å‹ï¼Œè¯·å®‰è£…transformers", "available": False}
        
        try:
            sentences = text.split('\n')[:20]
            results = []
            
            for sentence in sentences:
                if len(sentence.strip()) > 5:
                    result = self.model(sentence[:512])
                    results.append(result[0] if result else None)
            
            if not results:
                return {"error": "æ— æœ‰æ•ˆæ–‡æœ¬", "available": False}
            
            avg_score = sum(r.get('score', 0.5) for r in results if r) / len(results)
            
            return {
                "available": True,
                "overall_score": round(avg_score * 100, 2),
                "fluency": round(avg_score * 10, 1),
                "summary": "åŸºäºæœ¬åœ°BERTæ¨¡å‹è¯„ä¼°"
            }
        except Exception as e:
            return {"error": str(e), "available": False}


class RuleBasedEvaluator(AIQualityEvaluator):
    """åŸºäºè§„åˆ™çš„è¯„ä¼°å™¨ï¼ˆæ— éœ€APIï¼‰"""
    
    async def evaluate(self, text: str) -> dict:
        issues = []
        scores = {
            "fluency": 7.0,
            "accuracy": 7.0,
            "localization": 7.0,
            "professionalism": 7.0
        }
        
        mt_patterns = [
            (r'çš„{3,}', 'è¿ç»­å¤šä¸ª"çš„"', -1),
            (r'äº†{3,}', 'è¿ç»­å¤šä¸ª"äº†"', -1),
            (r'æ˜¯{3,}', 'è¿ç»­å¤šä¸ª"æ˜¯"', -1),
            (r'æˆ‘æˆ‘æˆ‘|ä½ ä½ ä½ |ä»–ä»–ä»–', 'é‡å¤ä»£è¯', -1.5),
            (r'[ï¼Œã€‚ã€]{2,}', 'è¿ç»­æ ‡ç‚¹', -0.5),
        ]
        
        for pattern, desc, penalty in mt_patterns:
            matches = re.findall(pattern, text)
            if matches:
                issues.append(f"{desc}: {len(matches)}æ¬¡")
                scores["fluency"] += penalty
        
        unnatural = ['æ‰“å¼€ç¯', 'å…³é—­ç¯', 'è¿™æ˜¯éå¸¸', 'é‚£æ˜¯éå¸¸', 'åœ¨è¿™ä¸€ç‚¹ä¸Š']
        for phrase in unnatural:
            if phrase in text:
                issues.append(f"ä¸è‡ªç„¶è¡¨è¾¾: {phrase}")
                scores["localization"] -= 1
        
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        total_chars = len([c for c in text if not c.isspace()])
        chinese_ratio = chinese_chars / total_chars if total_chars > 0 else 0
        
        if chinese_ratio < 0.5:
            scores["accuracy"] -= 2
            issues.append(f"ä¸­æ–‡æ¯”ä¾‹è¿‡ä½: {chinese_ratio:.1%}")
        
        punct_count = len(re.findall(r'[ï¼Œã€‚ï¼ï¼Ÿã€]', text))
        punct_ratio = punct_count / total_chars if total_chars > 0 else 0
        
        if punct_ratio < 0.01:
            scores["fluency"] -= 1
            issues.append("ç¼ºå°‘æ ‡ç‚¹ç¬¦å·")
        
        for key in scores:
            scores[key] = max(0, min(10, scores[key]))
        
        overall = sum(scores.values()) / len(scores) * 10
        
        is_mt = overall < 60 or len(issues) > 3
        
        return {
            "available": True,
            "fluency": round(scores["fluency"], 1),
            "accuracy": round(scores["accuracy"], 1),
            "localization": round(scores["localization"], 1),
            "professionalism": round(scores["professionalism"], 1),
            "overall_score": round(overall, 2),
            "is_machine_translation": is_mt,
            "issues": issues,
            "summary": "åŸºäºè§„åˆ™è¯„ä¼°" + ("ï¼Œç–‘ä¼¼æœºå™¨ç¿»è¯‘" if is_mt else "")
        }


async def test_with_evaluator(evaluator: AIQualityEvaluator, evaluator_name: str, text: str) -> dict:
    """ä½¿ç”¨æŒ‡å®šè¯„ä¼°å™¨æµ‹è¯•"""
    print(f"\nä½¿ç”¨ {evaluator_name} è¯„ä¼°ä¸­...")
    start_time = time.time()
    
    result = await evaluator.evaluate(text)
    
    elapsed = time.time() - start_time
    result["evaluator"] = evaluator_name
    result["elapsed_time"] = round(elapsed, 2)
    
    return result


async def main():
    print("=" * 70)
    print("å­—å¹•è´¨é‡AIè¯„ä¼°æµ‹è¯•")
    print("=" * 70)
    
    print("\nè¯·é€‰æ‹©AIè¯„ä¼°æ–¹æ¡ˆï¼š")
    print("1. OpenAI API (éœ€è¦API Key)")
    print("2. DeepSeek API (éœ€è¦API Key)")
    print("3. æœ¬åœ°æ¨¡å‹ (éœ€è¦å®‰è£…transformers)")
    print("4. è§„åˆ™è¯„ä¼° (æ— éœ€API)")
    print("5. å…¨éƒ¨æµ‹è¯•")
    
    choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (1-5): ").strip()
    
    print("\næ­£åœ¨æœç´¢å­—å¹•...")
    client = ThunderClient()
    results = await client.search(query="ipx580")
    
    if not results:
        print("æœªæ‰¾åˆ°å­—å¹•")
        return
    
    print(f"æ‰¾åˆ° {len(results)} ä¸ªå­—å¹•")
    
    print("\næ­£åœ¨ä¸‹è½½ç¬¬ä¸€ä¸ªå­—å¹•...")
    subtitle = results[0]
    content_bytes = await client.download_bytes(url=subtitle.url, timeout_s=30)
    
    try:
        content = content_bytes.decode('utf-8')
    except UnicodeDecodeError:
        content = content_bytes.decode('gbk', errors='ignore')
    
    text = extract_text(content, subtitle.ext)
    
    print(f"\nå­—å¹•: {subtitle.name}")
    print(f"æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
    print(f"\næ–‡æœ¬é¢„è§ˆ (å‰500å­—ç¬¦):")
    print("-" * 50)
    print(text[:500])
    print("-" * 50)
    
    evaluators = []
    
    if choice in ['1', '5']:
        evaluators.append((OpenAIEvaluator(), "OpenAI"))
    if choice in ['2', '5']:
        evaluators.append((DeepSeekEvaluator(), "DeepSeek"))
    if choice in ['3', '5']:
        evaluators.append((LocalModelEvaluator(), "æœ¬åœ°æ¨¡å‹"))
    if choice in ['4', '5']:
        evaluators.append((RuleBasedEvaluator(), "è§„åˆ™è¯„ä¼°"))
    
    if not evaluators:
        print("æ— æ•ˆé€‰é¡¹")
        return
    
    print("\n" + "=" * 70)
    print("å¼€å§‹è¯„ä¼°")
    print("=" * 70)
    
    all_results = []
    
    for evaluator, name in evaluators:
        result = await test_with_evaluator(evaluator, name, text)
        all_results.append(result)
        
        print(f"\n{'='*50}")
        print(f"è¯„ä¼°å™¨: {name}")
        print(f"è€—æ—¶: {result.get('elapsed_time', 0)}ç§’")
        
        if result.get("available"):
            print(f"\nğŸ“Š è¯„ä¼°ç»“æœ:")
            print(f"  æµç•…åº¦: {result.get('fluency', 'N/A')}/10")
            print(f"  å‡†ç¡®åº¦: {result.get('accuracy', 'N/A')}/10")
            print(f"  æœ¬åœ°åŒ–: {result.get('localization', 'N/A')}/10")
            print(f"  ä¸“ä¸šæ€§: {result.get('professionalism', 'N/A')}/10")
            print(f"\n  â˜… ç»¼åˆè¯„åˆ†: {result.get('overall_score', 'N/A')}/100")
            print(f"  â˜… ç–‘ä¼¼æœºå™¨ç¿»è¯‘: {'æ˜¯' if result.get('is_machine_translation') else 'å¦'}")
            
            if result.get('issues'):
                print(f"\n  å‘ç°çš„é—®é¢˜:")
                for issue in result['issues'][:5]:
                    print(f"    - {issue}")
            
            print(f"\n  è¯„ä»·: {result.get('summary', 'N/A')}")
        else:
            print(f"\nâŒ è¯„ä¼°å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    
    print("\n" + "=" * 70)
    print("è¯„ä¼°æ±‡æ€»")
    print("=" * 70)
    
    available_results = [r for r in all_results if r.get("available")]
    
    if available_results:
        print(f"\n{'è¯„ä¼°å™¨':<15} {'è¯„åˆ†':<10} {'MTåˆ¤å®š':<10} {'è€—æ—¶'}")
        print("-" * 50)
        for r in available_results:
            mt_str = "æ˜¯" if r.get('is_machine_translation') else "å¦"
            print(f"{r['evaluator']:<15} {r.get('overall_score', 'N/A'):<10} {mt_str:<10} {r.get('elapsed_time', 0)}s")
    
    print("\n" + "=" * 70)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 70)


if __name__ == "__main__":
    asyncio.run(main())
